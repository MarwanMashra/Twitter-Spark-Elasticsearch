{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249fea40-d7fd-48d3-a4b5-b44d5c359954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.8/636.8 KB\u001b[0m \u001b[31m137.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk>=3.1\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m183.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.4.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.2/763.2 KB\u001b[0m \u001b[31m183.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk, textblob\n",
      "Successfully installed nltk-3.7 regex-2022.4.24 textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e2acf4-b794-407a-81ca-aeed78a69563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.mllib.clustering import StreamingKMeans\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from textblob import TextBlob\n",
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3436e",
   "metadata": {},
   "source": [
    "### Host + Ports (You may change this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"host.docker.internal\"   # if inside docker container\n",
    "# HOST = \"localhost\"            # if outside docker container \n",
    "\n",
    "STREAM_PORT = 4040     # the port to which your stream listenner is binded\n",
    "ELASTIC_PORT = 9200    # the port of your Elasticsearch server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773593c5",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b354b5a",
   "metadata": {},
   "source": [
    "### Spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local StreamingContext with batch interval of 10 second\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setCheckpointDir(\"spark_checkpoint\")    # important to use an invertible window operation later\n",
    "ssc = StreamingContext(sc, 10)\n",
    "\n",
    "# create a DStream for the tweets \n",
    "raw_tweets = ssc.socketTextStream(HOST, STREAM_PORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7ebf5",
   "metadata": {},
   "source": [
    "### Processing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a13827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acts as a label encoder [class -> int]\n",
    "tag_to_int = {}\n",
    "loc_to_int = {}\n",
    "\n",
    "def process_tweets(tweet):\n",
    "    tweet = json.loads(tweet)\n",
    "    \n",
    "    # for the label encoder\n",
    "    if tweet['tag'] not in tag_to_int:\n",
    "        tag_to_int[tweet['tag']] = len(tag_to_int)\n",
    "        \n",
    "    if tweet['location'] not in loc_to_int:\n",
    "        loc_to_int[tweet['location']] = len(loc_to_int)\n",
    "       \n",
    "    # sentiment analysis\n",
    "    polarity, subjectivity = TextBlob(tweet['text']).sentiment\n",
    "    return {\n",
    "        'text':tweet['text'],\n",
    "        'location':loc_to_int[tweet['location']],\n",
    "        'tag':tag_to_int[tweet['tag']],\n",
    "        'polarity':polarity,\n",
    "        'subjectivity':subjectivity\n",
    "    }\n",
    "\n",
    "# add the processing to the pipeline\n",
    "tweets = raw_tweets.map(process_tweets)\n",
    "train_data = tweets.map(lambda tweet: Vectors.dense([tweet['tag'], tweet['location'], tweet['polarity'], tweet['subjectivity']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca775b8",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StreamingKMeans(k=4, decayFactor=1.0).setRandomCenters(4, 1.0, 0)\n",
    "\n",
    "model.trainOn(train_data)\n",
    "result = model.predictOn(train_data)   # evaluate on the training data cuz don't know what else to evaluate on :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e42b39c",
   "metadata": {},
   "source": [
    "### Size of clusters (window operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ec710",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = result.map(lambda cluster: (f'cluster-{cluster+1}', 1))\n",
    "# window of size 30s, and slides by 10s (very arbitrary)\n",
    "clusterCounts = pairs.reduceByKeyAndWindow(lambda x, y: x + y, lambda x, y: x - y, 30, 10)\n",
    "\n",
    "# print the results\n",
    "clusterCounts.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5235f8f",
   "metadata": {},
   "source": [
    "### Start the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c57e5-a670-465a-af87-d4e10fe3ec6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:07:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:07:10\n",
      "-------------------------------------------\n",
      "('cluster-4', 6)\n",
      "('cluster-3', 2)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:07:20\n",
      "-------------------------------------------\n",
      "('cluster-4', 13)\n",
      "('cluster-3', 4)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:07:30\n",
      "-------------------------------------------\n",
      "('cluster-4', 16)\n",
      "('cluster-3', 8)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:07:40\n",
      "-------------------------------------------\n",
      "('cluster-4', 16)\n",
      "('cluster-3', 8)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:07:50\n",
      "-------------------------------------------\n",
      "('cluster-4', 19)\n",
      "('cluster-3', 7)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:08:00\n",
      "-------------------------------------------\n",
      "('cluster-4', 23)\n",
      "('cluster-3', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:08:10\n",
      "-------------------------------------------\n",
      "('cluster-4', 26)\n",
      "('cluster-3', 4)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:08:20\n",
      "-------------------------------------------\n",
      "('cluster-4', 23)\n",
      "('cluster-3', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:08:30\n",
      "-------------------------------------------\n",
      "('cluster-4', 24)\n",
      "('cluster-3', 4)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-06 10:08:40\n",
      "-------------------------------------------\n",
      "('cluster-4', 22)\n",
      "('cluster-3', 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ae76e",
   "metadata": {},
   "source": [
    "## Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006a1e4",
   "metadata": {},
   "source": [
    "### functions to handle the requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8c2d28d-c12e-4ade-aeb2-2b0b8cd37c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticsearch_curl(uri='', json_body='', verb='get', verbose=1):\n",
    "    # verbose : 0 => none, 1 => errors, 2 => all\n",
    "    uri = f'http://{HOST}:{ELASTIC_PORT}/'+uri\n",
    "    # pass header option for content type if request has a\n",
    "    # body to avoid Content-Type error in Elasticsearch v6.0\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # make HTTP verb parameter case-insensitive by converting to lower()\n",
    "        if verb.lower() == \"get\":\n",
    "            resp = requests.get(uri, headers=headers, data=json_body)\n",
    "        elif verb.lower() == \"post\":\n",
    "            resp = requests.post(uri, headers=headers, data=json_body)\n",
    "        elif verb.lower() == \"put\":\n",
    "            resp = requests.put(uri, headers=headers, data=json_body)\n",
    "\n",
    "        # read the text object string\n",
    "        try:\n",
    "            resp_text = json.loads(resp.text)\n",
    "        except:\n",
    "            resp_text = resp.text\n",
    "\n",
    "        # catch exceptions and print errors to terminal\n",
    "    except Exception as error:\n",
    "        resp_text = error\n",
    "        if verbose>=1:\n",
    "            print ('\\nelasticsearch_curl() error:', error)\n",
    "\n",
    "    if verbose>=2:\n",
    "        print(json.dumps(resp_text, sort_keys=False, indent=4))\n",
    "        \n",
    "    return resp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9406d71a-68a5-4cc4-9cf5-76e385fe8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_doc(rdd):\n",
    "    \"\"\" insert all tweets of the rdd in Elasticsearch\n",
    "\n",
    "    Args:\n",
    "        rdd (RDD): the rdd containing the tweets to insert\n",
    "    \"\"\"\n",
    "\n",
    "    # create the body (tweets)\n",
    "    body = \"\"\n",
    "    for tweet in rdd.collect():\n",
    "        body += '{ \"create\": { } }' + '\\n' + tweet + '\\n'\n",
    "\n",
    "    if body: # if there is at least one tweet\n",
    "\n",
    "        # send a PUT request to insert the tweets\n",
    "        response = elasticsearch_curl(\n",
    "            f'logs-my_app-default/_bulk?pretty',\n",
    "            verb='put',\n",
    "            json_body=body,\n",
    "            verbose=1\n",
    "        )\n",
    "        if 'errors' in response.keys() and not response['errors']:\n",
    "            print(f'{len(response[\"items\"])} tweets inserted')\n",
    "        else:\n",
    "            print(\"Failed to insert\")\n",
    "            \n",
    "def query(q):\n",
    "    \"\"\" run a query on the tweets\n",
    "\n",
    "    Args:\n",
    "        q (dict): a query to run\n",
    "    \"\"\"\n",
    "\n",
    "    # send a GET request\n",
    "    response = elasticsearch_curl(\n",
    "                '_search',\n",
    "                verb='get',\n",
    "                json_body=json.dumps(q),\n",
    "                verbose=1\n",
    "            )\n",
    "    \n",
    "    # print the matching results\n",
    "    hits = response['hits']['hits']\n",
    "    if len(hits)==0:\n",
    "        print(\"No match found\")\n",
    "    for hit in response['hits']['hits']:\n",
    "        print(json.dumps(hit['_source'], sort_keys=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9922750",
   "metadata": {},
   "source": [
    "### Start inserting tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299d531-f9e5-4c15-9c0c-76d82d68447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 tweet inserted\n",
      "9 tweet inserted\n",
      "9 tweet inserted\n",
      "12 tweet inserted\n",
      "7 tweet inserted\n",
      "7 tweet inserted\n"
     ]
    }
   ],
   "source": [
    "tweets = raw_tweets.foreachRDD(insert_doc)\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e09f8",
   "metadata": {},
   "source": [
    "### Run some queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d29840dc-07d6-442f-9ed1-d406c7a98678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"[$629.99]\\nASUS KO NVIDIA GeForce RTX 3070 V2 OC Edition 8GB GDDR6 Gami\\n#rtx3070 #geforce3070\\nSource: Amazon Checker v3Z\\nReason: Sold by Amazon\\n\\n\\ud83d\\uded2: \",\n",
      "    \"location\": \"Pittsburgh, PA\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"[$629.99]\\nASUS KO NVIDIA GeForce RTX 3070 V2 OC Edition 8GB GDDR6 Gami\\n#rtx3070 #geforce3070\\nSource: Amazon Checker v3Z\\nReason: Sold by Amazon\\n\\n\\ud83d\\uded2: \",\n",
      "    \"location\": \"Pittsburgh, PA\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"Check out \\\"Blinding Lights\\\" by The Weeknd on Amazon Music. \",\n",
      "    \"location\": \"\\u0191\\u0289\\u036bc\\u0367\\u043a\\u036d\\u03b9\\u036a\\u03b7\\u0363 Texas\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"@BrentBozell I have 4 kids. Why should amazon pay me?\",\n",
      "    \"location\": \"Selmer, TN\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"@peter3isamazing COME ON FUNKO &amp; AMAZON, DROP A WORKING LINK RIGHT NOW\",\n",
      "    \"location\": \"they/she 25\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"Deals: Amazon Introduces New BOGO 30% Off Sale on Collection of Apple\\u00a0Accessories \",\n",
      "    \"location\": \"Algeria\",\n",
      "    \"tag\": \"apple\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"Check out Un Verano Sin Ti [Explicit] by Bad Bunny on Amazon Music\\n\",\n",
      "    \"location\": \"Erlton, NJ\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"Amazon summer sale 2022: Enjoy as much as 90% off on gold plated jewellery  \",\n",
      "    \"location\": \"New Delhi, India\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"@amazonIN  If Amazon can not deliver on time why they are taking the order. \",\n",
      "    \"location\": \"India\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"Master Lock Magnum Solid Steel Padlock 4 Pack $26.99 at Amazon (reg. $48.39; SAVE 44%) \",\n",
      "    \"location\": \"St. Petersburg, FL\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "q = {\"query\": {\"match\": {\"text\":\"amazon\"}}}\n",
    "query(q);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2bdcc170-db9f-475a-96ee-8bbd648bcfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"RT @lowkey_harshita: Amazon people are the best \\ud83d\\ude2d\\ud83d\\ude2d\\n@PrimeVideoIN @AmazonHelp thank you for making our day.\\n\\n#KaranKundrra \",\n",
      "    \"location\": \"India\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @lowkey_harshita: Amazon people are the best \\ud83d\\ude2d\\ud83d\\ude2d\\n@PrimeVideoIN @AmazonHelp thank you for making our day.\\n\\n#KaranKundrra \",\n",
      "    \"location\": \"India\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @lowkey_harshita: Amazon people are the best \\ud83d\\ude2d\\ud83d\\ude2d\\n@PrimeVideoIN @AmazonHelp thank you for making our day.\\n\\n#KaranKundrra \",\n",
      "    \"location\": \"Mumbai, India\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"boAt Xtend Smartwatch with Alexa Built-in\\n\\n1.69\\u201d HD Display\\nMultiple Watch Faces\\nStress Monitor\\nSleep Monitor &amp; 5 ATM\\n\\nPrice - \\u20b92,399\\n\\nOffers - 5% back with Amazon Pay ICICI Bank credit card for Prime members. 3% back for others\\n\\n\\ud83d\\ude4fFollow us\\n\\n\",\n",
      "    \"location\": \"Chandigarh\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @MorePerfectUS: EXCLUSIVE: Amazon fired a worker named Ezra Hudson who vocally supported the union drive in Bessemer, AL.\\n\\nEzra's cowork\\u2026\",\n",
      "    \"location\": \"Toronto, Ontario\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @alexandergold: Sorry, can\\u2019t talk. Taylor Swift is releasing a re-recorded deep cut in sync with an Amazon Prime Video movie marketing c\\u2026\",\n",
      "    \"location\": \"\\ud83e\\udd0d\\u2600\\ufe0f\\ud83d\\udc52\\ud83c\\udf34\\ud83c\\udfac\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @USAahgases: \\ud83d\\udc23We are raising funds to support GOT7\\u2019s comeback!\\nFunds will be used to purchase digital album on US ITunes,Amazon,Tidal et\\u2026\",\n",
      "    \"location\": \".\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @TXTCHART_KR: .@TXT_members \\\"minisode2: Thursday's Child (TEAR version)\\\" is available for pre-order on Amazon Music, to be released on M\\u2026\",\n",
      "    \"location\": \"01' -txt,stayc\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @ddayen: \\u201cWhen workers try to organize, Amazon breaks the law,\\u201d said Teamsters general president Sean O\\u2019Brien. \\u201cWhy are we supporting th\\u2026\",\n",
      "    \"location\": \"Los Angeles, CA\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @meganlcook: Book history twitter: who is writing about the ubiquitous amazon listings for print-on-demand copies of public domain texts\\u2026\",\n",
      "    \"location\": \"The writing/recording closet.\",\n",
      "    \"tag\": \"amazon\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "q = {\n",
    "  \"query\": {\n",
    "    \"terms\": {\n",
    "      \"text\": [ \"apple\", \"samsung\" ],\n",
    "      \"boost\": 1.0\n",
    "    },\n",
    "      \"terms\": {\n",
    "      \"text\": [ \"amazon\" ],\n",
    "      \"boost\": 2.0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "query(q);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0f31c887-9ca9-43f2-a422-1e14a552e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"Know how to stay in touch with your contacts and get information during an emergency. Radio, TV and official social media accounts are the best places to get information. You can also mark yourself safe on Facebook during a disaster: \",\n",
      "    \"location\": \"Whitby, ON\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"@theharshpuniya @PitchGroundHQ @iuditg @elonmusk He is only on Twitter because he decided to buy it!\\n\\nHe isn't on Instagram, Facebook, snapchat,tinder,tiktok!\",\n",
      "    \"location\": \"Dhule, India\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @PopCrave: Beyonc\\u00e9 earns her first Daytime Emmy nomination in the original song category for her theme song to Facebook Watch\\u2019s \\u201cTalks w\\u2026\",\n",
      "    \"location\": \"Oakland, California \",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @kdlexfiles: happy 400k views on facebook!!\\n\\n#KDLexRunToMe \",\n",
      "    \"location\": \"twenty one\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @kdlexfiles: happy 400k views on facebook!!\\n\\n#KDLexRunToMe \",\n",
      "    \"location\": \"Manila, PH\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"RT @JamesSurowiecki: This is the woman who, in 2016, wrote the ultimate \\u201cdo your own research\\u201d line in a Facebook post: \\u201cThe Pope is the An\\u2026\",\n",
      "    \"location\": \"SoCal\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"@MuralsOnCanvas @SatisfiedSally @moneywisecom yes he is -- he literally has 40+ years in the field of virology \\n\\nyour facebook degree doesnt even come close to his expertise\\n\\ngood to know that you think your \\\"D\\\" grade average in high school qualifies you as an expert in virology\",\n",
      "    \"location\": \"United States\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"NEW: I have an exclusive interview with pitcher Chris Paddack about how he's keeping old-school stirrups alive. Really fun stuff!\\n\\nAvailable to my Premium Subscribers (Facebook account req'd): \",\n",
      "    \"location\": \"Brooklyn, NY\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"@HRHJohorII @TheJusticeDept \\n   Many in satanist lee hsien loong's criminals families want to kill themselves.\\nhis tamilman facebook terrorist nedumaran's and chinaman criminal \\\"regular talker\\\"'s mothers want to kill themselves out of total disgrace and shame.\\n   SOS can provide information.\",\n",
      "    \"location\": \"Johore, Malaysia\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n",
      "{\n",
      "    \"text\": \"Anyone checked Imys Facebook? Pfffft\\ud83d\\ude02 everything deleted, except his \\u2018humanitarian\\u2019 mission, stood in the rain. Has he done one to the starving people of Ukraine yet? \\nThought not. @bluenessie @bungle666ue @HTwelvetrees1 @Pmc1Bai @Drevil55919464 @TonyMar19b\",\n",
      "    \"location\": \"Oldham, England\",\n",
      "    \"tag\": \"facebook\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "q = {\n",
    "  \"query\": {\n",
    "    \"terms\": {\n",
    "      \"text\": [ \"facebook\"],\n",
    "      \"boost\": 1.0\n",
    "    }\n",
    "  },\n",
    "  \"highlight\": {\n",
    "    \"fields\": {\n",
    "      \"text\": {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "query(q);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
